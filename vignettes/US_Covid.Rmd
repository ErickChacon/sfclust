---
title: "Bayesian Spatial Functional Clustering with bsfc"
author: "Ruiman Zhong"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{1.Bayesian Spatial Functional Clustering with bsfc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

Disease surveillance relies heavily on accurately interpreting patterns to understand disease stages, manage, and prevent health crises. One important task is to detect neighboring regions with similar disease risks, aiding in identifying populations with high exposure, uncovering inequalities, and allocating resources based on risk levels. This vignette demonstrates how to use the `bsfc` package to perform Bayesian spatial functional clustering on COVID-19 data from the United States.

# Loading Necessary Packages

We begin by loading the required packages. These packages will assist with data manipulation, visualization, and running the `bsfc` algorithm.

```{r include=FALSE}
packages <- c("gridExtra", "deldir", "fields", "igraph", 
              "ggplot2", "Matrix.utils", "grid", "class", 
              "spdep", 'sf', 'bsfc','cccd','ggraph')

package.check <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE, repos = "http://cran.us.r-project.org")
    library(x, character.only = TRUE)
  } else {
    library(x, character.only = TRUE)
  }
})
```

# Loading and Preparing the Data

We will use a pre-processed dataset that contains COVID-19 case counts (`Y`), population data (`N`), and a `map` object representing the spatial layout of the regions.

The data is stored in `.rds` format and will be loaded for analysis.

```{r}
data("us_covid_clean")

# Extract relevant information from the dataset
Y <- as.matrix(us_covid_clean$Y)   # COVID-19 case counts
N <- us_covid_clean$N              # Population data
ratio <- colMeans(Y / N)           # Calculate the ratio of cases to population
E <- sweep(N, MARGIN = 2, STATS = ratio, `*`) # Expected counts based on population
nt <- dim(N)[1]                    # Number of time points
ns <- dim(N)[2]                    # Number of spatial regions
time <- seq(0, 1, length.out = nt) # Normalized time vector
map <- us_covid_clean$map          # Spatial map of the regions
```

# Running the Clustering Algorithm

We'll now use the `bsfc` function to perform clustering based on the preprocessed data. This step includes building a Minimum Spanning Tree (MST) and running the Bayesian spatial functional clustering algorithm.
The function `initial.mst.build` is to build a initial partition parameters (Graph, MST, cluster). We could generate the initial graph by different ways, like Kth nearest neighbor (`method` = 'knn') or using adjacency matrix like the follwing example. The number of the initial cluster is set by `nclust`. If the `weights` = NULL, means the weights of every egdge in the initial graph is random generated from U[0,1].

```{r warning=FALSE, fig.width=6, fig.height=4}
# Initialize the graph data using Minimum Spanning Tree (MST)
geodata <- initial.mst.build(map, method = 'adjmat', nclust = 10, weights = NULL, seed = 1234)
coords <- st_coordinates(st_centroid(map))
plotGraph(map,coords,geodata$graph,"Initial graph")
```

We could also check the initial MST and cluster memberships, by

```{r fig.width=6, fig.height=4}
plotMST(map,coords,geodata$mst,geodata$cluster, "Initial MST")
```


The plot illustrates that we have 10 initial clusters. 

Next, we will define the formula for the Bayesian spatial functional with-cluster model. Here we use AR 1 model, where `Yk` is the response of each cluster (Covid cases in the US), and `Xk` is the random effect. If covariates are provided, we could include them in the fixed effect. The package supports common model that `R-INLA` supports. For more information, please check `R-INLA`.
```{r}
# Define the formula for the Bayesian spatial functional model
formula <- Yk ~ f(Xk, model = "ar", order = 1) + f(id, model = "iid")
```
 
 `bsfc` is the main functions to implement Bayesian spatial functional clustering based on bayesian spanning tree.  `Y` is the response, here is the Covid cases in the US. X is the random effect vector, referring to the `Xk` of the formula. We fit a `poisson` likelihood with the offset  `N` = E, where E is the expected cases. Hyperparameter `c` describe the penalty of the number of the final cluster, ranging from 0 to 1. We don't need any correction when using ar model. We will run `nter` = 1000 MCMC chain, without burn-in procedure. 
 
 The results of the function is saved in the path_res.rds. Please define a valid address and name before running the function.
 
```{r eval=FALSE}
# define the path to save the final results, euns for one hour
path <- '~/Documents/project3'
path_res <- file.path(path, "data", "result","US_cluster.rds")
# Run the bsfc algorithm with the defined parameters
bsfc(Y, graphdata = geodata, X = time, N = E, formula = formula, 
     family = "poisson", hyperpar = list(c = 0.5), 
     correction = FALSE, niter = 1000, burnin = 0, 
     thin = 1, path_save = path_res)
```

# Analyzing the Results

After running the model, we can analyze the results, including the final model and cluster assignments. There are five components in total in the results: the each cluster membership at each step, the related marginal likelihood at each step, the MST at each step, and the final estimated INLA model results.

Let's start by loading the initial results and analyzing the MCMC chain to assess convergence.

```{r fig.width=6, fig.height=4}
path <- '~/Documents/project3'
path_res <- file.path(path, "data", "result","US_cluster.rds")
# Load the results from the saved file
result <- readRDS(path_res)
plot(result$log_mlike, type = "l", main = "Marginal Likelihoods of the Initial MCMC Run",
     xlab = "Iteration", ylab = "Marginal Likelihood")
```


The plot above shows the marginal likelihoods across iterations. If the plot indicates that the chain has not converged, we can continue the MCMC process.

# Continuing the MCMC Process
Next, we'll use the continue_bsfc function to extend the MCMC process by adding 2000 more iterations.
```{r}
# Define the additional MCMC settings
niter_additional <- 1000
time <- seq(0, 1, length.out = nt)
path_res <- file.path(path, "data", "result","US_cluster2.rds")
```
Run the continuation of the BSFC process
```{r eval=FALSE}
# the function runs for one hour
continue_bsfc(result,
  Y = Y, X = time, N = E, graph = geodata$graph,
  formula = formula, family = "poisson", hyperpar = list(c = 0.5),
  correction = FALSE, niter = niter_additional, burnin = 0, thin = 1,
  path_save = path_res
)
```
# Analyzing the Continued Results

After running the additional MCMC iterations, we can load and analyze the updated results to check for convergence.
```{r, fig.width=6, fig.height=4}
result_continue <- readRDS(path_res)  # Load the continued results into the workspace
mlik <- c(result$log_mlike, result_continue$log_mlike)
# Plot the updated marginal likelihoods
plot(mlik, type = "l", main = "Marginal Likelihoods After Continued MCMC Run",
     xlab = "Iteration", ylab = "Marginal Likelihood")
```

Print the final cluster_membership and plot.

```{r fig.width=6, fig.height=4}
clust_res = result_continue$cluster[length(result_continue$mst),]
clust_res
plotClusterMap(clust_res, NULL, map, NULL,title = " ",fill = "Cluster", filepath = NULL)
```

### Check the fitted curves and time series of each cluster
```{r warning=FALSE, fig.width=6, fig.height=4}
library(dplyr)
start_date <- as.Date('2020-01-20')
end_date <- as.Date('2021-01-04')

# Generate a sequence of weekly dates
time <- seq.Date(from = start_date, to = end_date, by = "week")
final_model = result_continue$model

level <- as.numeric(levels(as.factor(clust_res)))
  ydf = setNames(as.data.frame(Y / E), 1:ns) |>
    mutate(time = time) |>
    tidyr::pivot_longer(1:ns, names_to = "region", names_transform = as.numeric) |>
    mutate(cluster = clust_res[region])
  cluster2 = rep(level, table(clust_res))
  preddf = purrr::map(level, function(x) final_model[[x]]$summary.fitted.values$mean / exp(final_model[[x]]$summary.random[['id']]$mean)) %>%
    purrr::map(~ matrix(., nrow = length(time))) %>%
    do.call(cbind, .) |>
    as.data.frame() |>
    setNames(1:49) |>
    mutate(time =  time) |>
    tidyr::pivot_longer(1:49, names_to = "newregion", names_transform = as.numeric) |>
    mutate(cluster = factor(cluster2[newregion]))
  # Define the custom labeller function
  custom_labeller <- function(cluster) {
    return(paste("Cluster", cluster))
  }

  # Apply the custom labeller to the facets
  p <- ggplot(ydf) +
    geom_line(aes(x = time, y = value, group = region), color = "gray", linewidth = 0.2) +
    geom_line(data = preddf, aes(x = time, y = value, group = newregion),
              color = "red", linewidth = 0.3) +
    facet_wrap(~ cluster, ncol = 4, scales = "free_y", labeller = labeller(cluster = as_labeller(custom_labeller))) +
    theme_bw() +
    theme(legend.position = "none", legend.text = element_text(size = 7)) +
    labs(color = "Cluster", y = "Relative Risk", x = "Time")

custom_breaks <- seq.Date(from = start_date, to = end_date, by = "8 weeks")

g = p  +
  scale_x_date(date_labels = "%b %d", breaks = custom_breaks) +  # Format x-axis labels to show month and day
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
g
```

# Conclusion

This vignette illustrated how to use the `bsfc` package to perform spatial functional clustering on a real-world dataset. The results can help in understanding the spatial distribution of COVID-19 cases and identifying regions with similar outbreak patterns.
